------------------------------------------------
Initial SLURM_ARRAY_TASK_ID: '9'
Validated SLURM_ARRAY_TASK_ID: 9
------------------------------------------------
DEBUG: NUM_DATASETS=3, NUM_EXPERIMENTS=9, TOTAL_TASKS=27
------------------------------------------------
SLURM Job ID: 2174751
SLURM Array Job ID: 2174740
SLURM Array Task ID: 9 / 27
Running on host: ccc0367.campuscluster.illinois.edu
Node allocated: ccc0367
Requested CPUs: 16
Running Dataset: SNLI
Running Experiment (Model Type): experiment-6
Sample Size: 10000 (8000 train, 1000 validation, 1000 test)
------------------------------------------------
Modules loaded.
Python environment 'IS567' activated: /sw/apps/anaconda3/2024.10/bin/python
OMP_NUM_THREADS set to 16
Changed directory to /u/jywu3/scratch/IS567FP
Starting Python script for SNLI / experiment-6 (Task ID 9)...
2025-05-11 22:41:44,864 - datasets - INFO - [config.py:54] - PyTorch version 2.6.0+cu126 available.
2025-05-11 22:41:48,177 - __main__ - INFO - [main.py:47] - Running mode: train
2025-05-11 22:41:48,177 - __main__ - INFO - [main.py:48] - Selected model type: experiment-6
2025-05-11 22:41:48,177 - __main__ - INFO - [main.py:49] - Selected dataset: SNLI
2025-05-11 22:41:48,177 - __main__ - INFO - [main.py:50] - Using device: cpu
2025-05-11 22:41:48,177 - __main__ - INFO - [main.py:52] - Using sample size: 10000
2025-05-11 22:41:48,177 - __main__ - INFO - [main.py:92] - Starting training for model: experiment-6
2025-05-11 22:41:48,255 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:55] - Initialized ExperimentTrainer for model key: 'experiment-6', class: GradientBoostingTFIDFSyntacticExperiment6, dataset: SNLI, suffix: sample10000
2025-05-11 22:41:48,255 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:71] - Initializing model instance for experiment-6 (GradientBoostingTFIDFSyntacticExperiment6)
2025-05-11 22:41:48,255 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:121] - Initialized GradientBoosting_TFIDF_Syntactic_Exp6 with params: {'n_estimators': 100, 'learning_rate': 3e-05, 'max_depth': None, 'random_state': 42, 'tfidf_max_features': 10000, 'tfidf_ngram_range': (1, 2), 'scale_syntactic': True}
2025-05-11 22:41:48,255 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:93] - Model experiment-6 initialized successfully.
2025-05-11 22:41:48,255 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:107] - --- Loading Pre-computed Features for experiment-6 on SNLI (train/sample10000) ---
2025-05-11 22:41:48,255 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:115] - Loading pre-computed features using SimpleParquetLoader...
2025-05-11 22:41:48,255 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:128] - Attempting to load feature file matching: dataset='SNLI', split='train', suffix='sample10000'
2025-05-11 22:41:48,255 - models.baseline_base - INFO - [baseline_base.py:622] - SimpleParquetLoader: Searching for features in cache/parquet/SNLI/train for SNLI/train/sample10000
2025-05-11 22:41:48,691 - models.baseline_base - INFO - [baseline_base.py:685] - SimpleParquetLoader: Loading final features from: cache/parquet/SNLI/train/SNLI_train_features_stats_syntactic_full.parquet
2025-05-11 22:41:49,122 - models.baseline_base - INFO - [baseline_base.py:687] - SimpleParquetLoader: Loaded 549367 rows from cache/parquet/SNLI/train/SNLI_train_features_stats_syntactic_full.parquet
2025-05-11 22:41:49,122 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:153] - Loaded 549367 rows with 250 columns from pre-computed feature file.
2025-05-11 22:41:49,126 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:163] - Feature data cleaned. 549367 samples remaining.
2025-05-11 22:41:49,126 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:172] - Extracting/Selecting features using experiment-6.extract_features...
2025-05-11 22:41:49,126 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:292] - GradientBoosting_TFIDF_Syntactic_Exp6: Fitting feature pipeline and transforming training data...
2025-05-11 22:41:49,126 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:232] - GradientBoosting_TFIDF_Syntactic_Exp6: Building unfitted feature pipeline...
2025-05-11 22:41:49,126 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:263] - Adding StandardScaler (via SparseScaler) for syntactic features.
2025-05-11 22:41:49,126 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:266] - Including 240 syntactic features in pipeline.
2025-05-11 22:41:49,126 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:277] - GradientBoosting_TFIDF_Syntactic_Exp6: Unfitted feature pipeline built.
2025-05-11 22:42:03,497 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:309] - Pipeline fit & transform complete in 14.37s. Shape: (549367, 10240)
2025-05-11 22:42:03,497 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:182] - Training features prepared. Shape: (549367, 10240)
2025-05-11 22:42:03,497 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:183] - Training labels prepared. Length: 549367
2025-05-11 22:42:03,633 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:194] - Data loading and preparation phase finished in 15.38s
2025-05-11 22:42:03,633 - models.base_experiment_trainer - INFO - [base_experiment_trainer.py:198] - --- Starting model training for experiment-6 on SNLI (sample10000) ---
2025-05-11 22:42:03,633 - models.gradient_boosting_tfidf_syntactic_experiment_6 - INFO - [gradient_boosting_tfidf_syntactic_experiment_6.py:347] - Converting sparse training data to dense for Gradient Boosting.
